{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/hlt/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from filelock import FileLock\n",
    "from transformers import AdamW, get_scheduler, set_seed\n",
    "\n",
    "from transformers.file_utils import is_offline_mode\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from args import parse_args\n",
    "from data_loader import raw_data_loader, data_processor\n",
    "from model_loader import model_loader\n",
    "from rouge_s import py_rouge_scores\n",
    "from scoring import bleu_scores, meteor_scores\n",
    "from utils import label_smoothed_nll_loss, postprocess_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    output_dir = \"./output/run_mask_finetune_dialogsum500-1k_bart_base\"\n",
    "    train_file = \"./data/samsum/train_small.csv\"\n",
    "    validation_file = \"./data/samsum/val_small.csv\"\n",
    "    test_file = \"./data/samsum/test_small.csv\"\n",
    "    text_column = \"dialogue\"\n",
    "    summary_column = \"summary\"\n",
    "#     model_name_or_path = \"t5-base\"\n",
    "    model_name_or_path = \"./output/run_mask_finetune_dialogsum500-1k_bart_base/best\"\n",
    "    model_type = \"bart\"\n",
    "    source_prefix = \"\"\n",
    "    max_source_length = 1024\n",
    "    min_target_length = 1\n",
    "    max_target_length = 128\n",
    "    learning_rate = 5e-5\n",
    "    weight_decay = 1e-3\n",
    "    label_smoothing = 0.1\n",
    "    length_penalty = 1.0\n",
    "    num_train_epochs = 4\n",
    "    per_device_train_batch_size = 1\n",
    "    gradient_accumulation_steps = 16\n",
    "    per_device_eval_batch_size = 1\n",
    "    per_device_test_batch_size = 1\n",
    "    num_warmup_steps = 0\n",
    "    cache_dir = \"./output/cache\"\n",
    "    overwrite_cache = True\n",
    "    seed = 12345\n",
    "    \n",
    "    ignore_pad_token_for_loss = True\n",
    "    preprocessing_num_workers = None\n",
    "    overwrite_cache = None\n",
    "    num_beams = None\n",
    "    pad_to_max_length = True\n",
    "    config_name = None\n",
    "    tokenizer_name = \"t5-base\"\n",
    "    use_slow_tokenizer = True\n",
    "    max_train_steps = None\n",
    "    lr_scheduler_type = \"linear\"\n",
    "    shuffle = False\n",
    "    \n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =  =  =  =  =  =  =  =  =  = Logging Setup =  =  =  =  =  =  =  =  =  =  =  = \n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =  =  =  =  =  =  =  =  =  = Pre-check Package Info =  =  =  =  =  =  =  =  =  =  =  = \n",
    "require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/summarization/requirements.txt\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except (LookupError, OSError):\n",
    "    if is_offline_mode():\n",
    "        raise LookupError(\n",
    "            \"Offline mode: run this script without TRANSFORMERS_OFFLINE first to download nltk data files\"\n",
    "        )\n",
    "    with FileLock(\".lock\") as lock:\n",
    "        nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = = = = = = = = = = = Main Process = = = = = = = = = = = = = = = = = =\n",
    "# Initialize the accelerator. The accelerator will handle device placement for us.\n",
    "accelerator = Accelerator()\n",
    "logger.info(accelerator.state)\n",
    "\n",
    "# Setup logging, we only want one process per machine to log things on the screen.\n",
    "# accelerator.is_local_main_process is only True for one process per machine.\n",
    "logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
    "if accelerator.is_local_main_process:\n",
    "    #datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    #datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "# If passed along, set the training seed now.\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed)\n",
    "    torch.backends.cudnn.enabled = False \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    if args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()\n",
    "\n",
    "# load raw dataset\n",
    "raw_datasets = raw_data_loader(args)\n",
    "\n",
    "# load model (config, tokenizer, s2s model)\n",
    "config, tokenizer, model = model_loader(accelerator, logger, args)\n",
    "\n",
    "# data processor (for DataLoader)\n",
    "dataloader, processed_dataset = data_processor(logger, args, accelerator, raw_datasets, tokenizer, model)\n",
    "train_dataloader, eval_dataloader, test_dataloader = dataloader\n",
    "train_dataset, _, _ = processed_dataset\n",
    "\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "config          = config.from_pretrained(args.output_dir+'/best')\n",
    "tokenizer       = tokenizer.from_pretrained(args.output_dir+'/best', config=config)\n",
    "unwrapped_model = unwrapped_model.from_pretrained(args.output_dir+'/best', config=config)\n",
    "model           = accelerator.prepare(unwrapped_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = EVAL =  =  =  =  =  =  =  =  =  =  =  =  =  =  = \n",
    "def generate_new(input_text):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tokenized = tokenizer([input_text], max_length=args.max_source_length, padding='max_length', truncation=True)\n",
    "        inputs, mask = tokenized[\"input_ids\"], tokenized[\"attention_mask\"]\n",
    "        inputs, mask = torch.tensor(inputs), torch.tensor(mask)\n",
    "        inputs = inputs.to(device=\"cuda:0\")\n",
    "        mask = mask.to(device=\"cuda:0\")\n",
    "\n",
    "        generated_tokens = accelerator.unwrap_model(model).generate(inputs, attention_mask = mask)\n",
    "        generated_tokens = accelerator.pad_across_processes(generated_tokens, dim=1, pad_index=tokenizer.pad_token_id)\n",
    "        generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "        dialogue_output = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "        \n",
    "    return dialogue_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_overlap(summary_list, utterance_list):\n",
    "    count = 0\n",
    "    \n",
    "    for word in utterance_list:\n",
    "        if word in summary_list:\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_bucket(utterance_list):\n",
    "    length = len(utterance_list)\n",
    "    \n",
    "    if length <= 4:\n",
    "        return \"S\"\n",
    "    if length > 10:\n",
    "        return \"L\"\n",
    "    \n",
    "    return \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input(summary, dialogue, i):\n",
    "    dialogue_sep = dialogue.split('\\n')\n",
    "    length = len(dialogue_sep)\n",
    "\n",
    "    input_str = \"Summary - \" + summary + \"\\n\" + \"Dialogue - \\n\"\n",
    "\n",
    "    speaker = dialogue_sep[i].split(':')[0]\n",
    "    target = dialogue_sep[i].split(':')[1]\n",
    "\n",
    "    speaker = \"Speaker - \" + speaker + \"\\n\"\n",
    "\n",
    "    overlap = string_overlap(summary.split(), target.split())\n",
    "    total = len(summary.split())\n",
    "    add_info = \"Overlap - \" + str(overlap) + \", Total - \" + str(total) + \"\\n\"\n",
    "\n",
    "    length_info = \"Length - \" + length_bucket(target.split())\n",
    "\n",
    "    temp_dialogue = dialogue_sep.copy()\n",
    "    temp_dialogue[i] = \"<mask>\"\n",
    "    temp_dialogue = '\\n'.join(temp_dialogue)\n",
    "\n",
    "    return input_str + temp_dialogue + '\\n\\n' + speaker + add_info + length_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_dialogue(dialogue, i, new_utterance):\n",
    "    dialogue_sep = dialogue.split('\\n')\n",
    "\n",
    "    speaker = dialogue_sep[i].split(':')[0]\n",
    "    target = dialogue_sep[i].split(':')[1]\n",
    "\n",
    "    temp_dialogue = dialogue_sep.copy()\n",
    "    temp_dialogue[i] = speaker + \":\" + new_utterance\n",
    "    temp_dialogue = '\\n'.join(temp_dialogue)\n",
    "\n",
    "    return temp_dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/dialogsum/dialogsum.train.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "id_list       = [sample['fname'] for sample in data]\n",
    "dialogue_list = [sample['dialogue'] for sample in data]\n",
    "summary_list  = [sample['summary'] for sample in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Do you have any experience working with a computer?\n",
      "#Person2#: Yes. I have been a data entry operator for three years.\n",
      "#Person1#: What kind of software can you use?\n",
      "#Person2#: I have working knowledge of Windows and Dos. Actually, I'm quite familiar with both Java and C Programming Languages.\n",
      "#Person1#: Do you have any other computer qualifications?\n",
      "#Person2#: I have an ACRE certificate, GRADE 2.\n",
      "#Person1#: Do you know how to use a PC to process the management information?\n",
      "#Person2#: I'm sorry to say I'm not familiar with processing management information, but I'm sure I could learn quite quickly. It can't be too difficult, and I've got a quick mind. I can handle any problem you give me.\n"
     ]
    }
   ],
   "source": [
    "dialogue = dialogue_list[123]\n",
    "print(dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1# interviews #Person2# who has been a data entry operator for three years. #Person2# knows how to use the software, has computer qualifications, and can learn quite quickly.\n"
     ]
    }
   ],
   "source": [
    "summary = summary_list[123]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary - #Person1# interviews #Person2# who has been a data entry operator for three years. #Person2# knows how to use the software, has computer qualifications, and can learn quite quickly.\n",
      "Dialogue - \n",
      "#Person1#: Do you have any experience working with a computer?\n",
      "#Person2#: Yes. I have been a data entry operator for three years.\n",
      "<mask>\n",
      "#Person2#: I have working knowledge of Windows and Dos. Actually, I'm quite familiar with both Java and C Programming Languages.\n",
      "#Person1#: Do you have any other computer qualifications?\n",
      "#Person2#: I have an ACRE certificate, GRADE 2.\n",
      "#Person1#: Do you know how to use a PC to process the management information?\n",
      "#Person2#: I'm sorry to say I'm not familiar with processing management information, but I'm sure I could learn quite quickly. It can't be too difficult, and I've got a quick mind. I can handle any problem you give me.\n",
      "\n",
      "Speaker - #Person1#\n",
      "Overlap - 1, Total - 28\n",
      "Length - M\n"
     ]
    }
   ],
   "source": [
    "model_input = generate_input(summary, dialogue, i)\n",
    "print(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Do you have any experience in using the software?\n"
     ]
    }
   ],
   "source": [
    "output = generate_new(model_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Do you have any experience working with a computer?\n",
      "#Person2#: Yes. I have been a data entry operator for three years.\n",
      "#Person1#: Do you have any experience in using the software?\n",
      "#Person2#: I have working knowledge of Windows and Dos. Actually, I'm quite familiar with both Java and C Programming Languages.\n",
      "#Person1#: Do you have any other computer qualifications?\n",
      "#Person2#: I have an ACRE certificate, GRADE 2.\n",
      "#Person1#: Do you know how to use a PC to process the management information?\n",
      "#Person2#: I'm sorry to say I'm not familiar with processing management information, but I'm sure I could learn quite quickly. It can't be too difficult, and I've got a quick mind. I can handle any problem you give me.\n"
     ]
    }
   ],
   "source": [
    "new_dialogue = generate_new_dialogue(dialogue, i, output)\n",
    "print(new_dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace ONE utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12460"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_len = len(dialogue_list)\n",
    "list_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "\n",
    "for i in range(list_len):\n",
    "    dialogue = dialogue_list[i]\n",
    "    summary = summary_list[i]\n",
    "    \n",
    "    dialogue_sep = dialogue.split('\\n')\n",
    "    length = len(dialogue_sep)\n",
    "    \n",
    "    j = random.randint(0, length-1)\n",
    "    \n",
    "    model_input = generate_input(summary, dialogue, j)\n",
    "    output = generate_new(model_input)\n",
    "    new_dialogue = generate_new_dialogue(dialogue, j, output)\n",
    "    \n",
    "    dct = {}\n",
    "    dct['fname'] = 'extra_' + str(i)\n",
    "    dct['dialogue'] = new_dialogue\n",
    "    dct['summary'] = summary\n",
    "    \n",
    "    \n",
    "    new_list.append(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Do you think Mr. Becket would be qualified for this job?\n",
      "#Person2#: Mr. Becket? I'm not sure. He is a nice fellow, of course, and easy to get along with. But I doubt his professional expertise. I want someone who can get the job done.\n"
     ]
    }
   ],
   "source": [
    "print(new_list[x]['dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Who do you think should get the job? How about Mr. Becket?\n",
      "#Person2#: Mr. Becket? I'm not sure. He is a nice fellow, of course, and easy to get along with. But I doubt his professional expertise. I want someone who can get the job done.\n"
     ]
    }
   ],
   "source": [
    "print(dialogue_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2# doesn't think Mr. Becket is qualified for the job\n"
     ]
    }
   ],
   "source": [
    "print(new_list[x]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2# doesn't think Mr. Becket is qualified for the job\n"
     ]
    }
   ],
   "source": [
    "print(summary_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': 'train_0',\n",
       " 'dialogue': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\",\n",
       " 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\",\n",
       " 'topic': 'get a check-up'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': 'extra_12345',\n",
       " 'dialogue': \"#Person1#: Do you think Mr. Becket would be qualified for this job?\\n#Person2#: Mr. Becket? I'm not sure. He is a nice fellow, of course, and easy to get along with. But I doubt his professional expertise. I want someone who can get the job done.\",\n",
       " 'summary': \"#Person2# doesn't think Mr. Becket is qualified for the job\"}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Fixed Utterance Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterance_list_from_length(length, mask_perc):\n",
    "    list_sz = int(length * mask_perc)\n",
    "    if list_sz < 1:\n",
    "        list_sz = 1\n",
    "    \n",
    "    rand_list = np.arange(length)\n",
    "    np.random.shuffle(rand_list)\n",
    "    rand_list = rand_list[:list_sz].tolist()\n",
    "    rand_list.sort()\n",
    "    \n",
    "    return rand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 6, 10, 11, 14]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_list_from_length(15, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12460"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_len = len(dialogue_list)\n",
    "list_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_list_arr = []\n",
    "\n",
    "for i in range(list_len):\n",
    "    dialogue = dialogue_list[i]\n",
    "    dialogue_sep = dialogue.split('\\n')\n",
    "    length = len(dialogue_sep)\n",
    "    \n",
    "    utterance_list = utterance_list_from_length(length, 0.4)\n",
    "    \n",
    "    utterance_list_arr.append(utterance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"fixed_utterance_list.json\", \"w\") as f:\n",
    "#     json.dump(utterance_list_arr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace 30-40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fixed_utterance_list.json\") as f:\n",
    "    fixed_utterance_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    dialogue = dialogue_list[i]\n",
    "    summary = summary_list[i]\n",
    "    \n",
    "    dialogue_sep = dialogue.split('\\n')\n",
    "    length = len(dialogue_sep)\n",
    "    \n",
    "    utterance_list = fixed_utterance_list[i]\n",
    "    \n",
    "    for j in utterance_list:\n",
    "        model_input = generate_input(summary, dialogue, j)\n",
    "        output = generate_new(model_input)\n",
    "        output = output.replace('\\n',\" \")\n",
    "        dialogue = generate_new_dialogue(dialogue, j, output)\n",
    "    \n",
    "    dct = {}\n",
    "    dct['fname'] = 'extra_' + str(i)\n",
    "    dct['dialogue'] = dialogue\n",
    "    dct['summary'] = summary\n",
    "    \n",
    "    new_list.append(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Hello. I would like to ask you about the customer service.\n",
      "#Person2#: Yes, I have a problem with the vacuum. It is broken.\n",
      "#Person1#: Is it under warranty?\n",
      "#Person2#: I think so. I bought it four months ago.\n",
      "#Person1#: Yes, it is still covered by our warranty. Tell me the mode number of your vacuum, please.\n",
      "#Person2#: Okay. The model number is 6594 - c.\n",
      "#Person1#: What is the name of your office?\n",
      "#Person2#: 906 Ottawa street. My name is David Yang. My phone number is 713-786-0234.\n",
      "#Person1#: Okay. There are two Customer Service Offices in your area. The nearest one is Chadwick and Hacks Appliances.\n",
      "#Person2#: Could you tell me where the office is located?\n",
      "#Person1#: Sure. 878 Fennel South.\n",
      "#Person2#: Okay. I will call them right away.\n",
      "#Person1#: Please let me know when you have the time.\n",
      "#Person2#: Okay. Thank you for your help.\n",
      "#Person1#: My pleasure.\n"
     ]
    }
   ],
   "source": [
    "print(new_list[x]['dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Hi. This is the Customer Service. How can I help you?\n",
      "#Person2#: Hi. I bought one of your vacuums from spend-wart. It's broken now.\n",
      "#Person1#: Is it under warranty?\n",
      "#Person2#: I think so. I bought it four months ago.\n",
      "#Person1#: Yes, it is still covered by our warranty. Tell me the mode number of your vacuum, please.\n",
      "#Person2#: Okay. The model number is 6594 - c.\n",
      "#Person1#: What's your address, your name and your phone number?\n",
      "#Person2#: 906 Ottawa street. My name is David Yang. My phone number is 713-786-0234.\n",
      "#Person1#: Okay. There are two Customer Service Offices in your area. The nearest one is Chadwick and Hacks Appliances.\n",
      "#Person2#: Could you tell me where the office is located?\n",
      "#Person1#: Sure. 878 Fennel South.\n",
      "#Person2#: Oh, I know that place. It's only two minutes drive.\n",
      "#Person1#: You have to call the office first.\n",
      "#Person2#: All right. Thank you very much for your help.\n",
      "#Person1#: My pleasure.\n"
     ]
    }
   ],
   "source": [
    "print(dialogue_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2# phones the Customer Service because #Person2#'s vacuum's broken. #Person1# answers the phone, asks for more details, and tells #Person1# the location of the nearest Customer Service Office.\n"
     ]
    }
   ],
   "source": [
    "print(new_list[x]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2# phones the Customer Service because #Person2#'s vacuum's broken. #Person1# answers the phone, asks for more details, and tells #Person1# the location of the nearest Customer Service Office.\n"
     ]
    }
   ],
   "source": [
    "print(summary_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': 'train_0',\n",
       " 'dialogue': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\",\n",
       " 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\",\n",
       " 'topic': 'get a check-up'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': 'extra_69',\n",
       " 'dialogue': '#Person1#: Hello. I would like to ask you about the customer service.\\n#Person2#: Yes, I have a problem with the vacuum. It is broken.\\n#Person1#: Is it under warranty?\\n#Person2#: I think so. I bought it four months ago.\\n#Person1#: Yes, it is still covered by our warranty. Tell me the mode number of your vacuum, please.\\n#Person2#: Okay. The model number is 6594 - c.\\n#Person1#: What is the name of your office?\\n#Person2#: 906 Ottawa street. My name is David Yang. My phone number is 713-786-0234.\\n#Person1#: Okay. There are two Customer Service Offices in your area. The nearest one is Chadwick and Hacks Appliances.\\n#Person2#: Could you tell me where the office is located?\\n#Person1#: Sure. 878 Fennel South.\\n#Person2#: Okay. I will call them right away.\\n#Person1#: Please let me know when you have the time.\\n#Person2#: Okay. Thank you for your help.\\n#Person1#: My pleasure.',\n",
       " 'summary': \"#Person2# phones the Customer Service because #Person2#'s vacuum's broken. #Person1# answers the phone, asks for more details, and tells #Person1# the location of the nearest Customer Service Office.\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dialogsum/dialogsum.finetune0-500.jsonl', 'w') as outfile:\n",
    "    for entry in new_list[:500]:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/dialogsum/dialogsum.finetune0-500.jsonl'\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "id_list       = [sample['fname'] for sample in data]\n",
    "dialogue_list = [sample['dialogue'] for sample in data]\n",
    "summary_list  = [sample['summary'] for sample in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: Hello. I would like to ask you about the customer service.\n",
      "#Person2#: Yes, I have a problem with the vacuum. It is broken.\n",
      "#Person1#: Is it under warranty?\n",
      "#Person2#: I think so. I bought it four months ago.\n",
      "#Person1#: Yes, it is still covered by our warranty. Tell me the mode number of your vacuum, please.\n",
      "#Person2#: Okay. The model number is 6594 - c.\n",
      "#Person1#: What is the name of your office?\n",
      "#Person2#: 906 Ottawa street. My name is David Yang. My phone number is 713-786-0234.\n",
      "#Person1#: Okay. There are two Customer Service Offices in your area. The nearest one is Chadwick and Hacks Appliances.\n",
      "#Person2#: Could you tell me where the office is located?\n",
      "#Person1#: Sure. 878 Fennel South.\n",
      "#Person2#: Okay. I will call them right away.\n",
      "#Person1#: Please let me know when you have the time.\n",
      "#Person2#: Okay. Thank you for your help.\n",
      "#Person1#: My pleasure.\n"
     ]
    }
   ],
   "source": [
    "print(dialogue_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2# phones the Customer Service because #Person2#'s vacuum's broken. #Person1# answers the phone, asks for more details, and tells #Person1# the location of the nearest Customer Service Office.\n"
     ]
    }
   ],
   "source": [
    "print(summary_list[x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
